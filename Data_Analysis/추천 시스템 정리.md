# 추천 시스템 정리

> 사용자에게 적절한 중고거래 물품을 추천하기 위한 추천 시스템입니다.
>
> 1. 각각의 중고거래 물품은 423개의 카테고리로 분류되어 있습니다.
> 2. 사용자의 조회 기록을 기반으로 사용자의 선호 카테고리를 예측합니다.
> 3. 해당 선호 카테고리의 물품을 사용자에게 추천합니다.



## 1. 추천 시스템 기초 작업

> 1. 추천 시스템 구성을 위한 데이터 생성 작업 (카테고리 / dummy data)
> 2. Model 평가를 위한 error 계산 방식 선정
> 3. Model 평가 방식

### 1.1 데이터 생성

1. 카테고리 선정 작업

    기존 쇼핑몰 사이트를 참고하여 11개 대분류 / 111개 중분류 / 423개 소분류 생성

    (추후 확장 가능성을 염두에 두고 DB를 구성)

2. dummy data 생성 작업

    카드사 데이터를 통해 성별/연령대별 선호 업종 및 카테고리 분석

    1. 46개의 유저 페르소나 선정 / 페르소나별로 20명의 유저 생성
    2. 각각의 페르소나에 주 카테고리 / 보조1 카테고리 / 보조2 카테고리 선정
    3. 각 유저에 대해 일정 범위 내의 값을 랜덤하게 가지는 조회수 데이터를 생성

### 1.2 Error 계산 방식

* RMSE 사용
    * 선정이유
        1. 직관적으로 이해하기 쉬움
        2. 우리 데이터의 특징을 잘 반영할 수 있음 (0이 매우 많음)
    * 문제점 : 크기 의존적인 측면이 존재함 (단, 다른 방식보다 우리 사이트에 더 적합함)
* 다른 방식을 사용하지 않은 이유
    * MAPE / sMAPE : 카테고리가 423개인데, 각각의 카테고리에 대해서 0번 조회한 경우가 자주 있음
    * RMSLE : Under Estimate에 큰 패널티를 줌
        * 실제 30번 / 20번으로 예측 : 실제 볼 제품을 적은 빈도로 추천
        * 실제 10번 / 20번으로 예측 : 보지 않을 제품을 잦은 빈도로 추천 (큰 패널티 필요)

### 1.3 Model 평가 방식

* 모든 Model은

    1. 75%를 train set / 25%를 test set으로 분리한 뒤
    2. train set으로 학습 후
    3. test set에 대한 예측값과 실제값을 기준으로 RMSE를 계산

    하여 평가를 진행함



## 2. 기본 추천 시스템

> 신규 유저 혹은 사이트 이용 내역이 거의 없는 유저를 위한 추천 시스템
>
> 유저를 성별 / 연령대로 분류하고, 해당 그룹의 평균 조회수를 예측 조회수로 계산합니다.
> (만약 해당 그룹의 조회 기록이 없는 카테고리라면, 전체 유저의 평균 조회수를 예측값으로 합니다.)
>
> 만약 유저의 조회기록이 있다면 예측조회수에 유저의 조회기록을 더해서 예측값을 계산합니다.
> (유저가 자주 본 카테고리를 주로 추천하게 됩니다.)

### 2.1 언제 협업 필터링으로 전환 되는가

* 각각의 케이스에 대해 실험적으로 데이터를 넣고, error를 계산해봤습니다..

    1. 하나의 카테고리를 1번 / 여러번 조회한 경우

    2. 같은 중분류의 카테고리를 각각 1번 / 1번+여러번 / 각각 여러번 조회한 경우

    3. 같은 대분류 내의 다른 중분류의 카테고리를 각각 1번 / 1번+여러번 / 각각 여러번 조회한 경우

    4. 다른 대분류 내의 다른 중분류의 카테고리를 각각 1번 / 1번+여러번 / 각각 여러번 조회한 경우

        등 여러 케이스로 데이터를 구성했습니다.

* 데이터 구성 후에는 각각의 모델을 통해 예측값을 계산했고,

    예측값과 실제값을 이용하여 RMSE를 계산했습니다.

    (이 경우 train / test set으로 나눌 정도로 데이터를 생성하지 못해서 100% train set으로 활용했습니다.)

* 어떤 카테고리를 몇번 보는가에 따라 약간의 차이는 존재하지만,

    최소 2개 이상의 중분류에 속한 카테고리를 본다면 협업 필터링으로 전환해도 될 것이라고 판단했습니다.



## 3. 협업 필터링 추천 시스템

> IBCF와 SVD 알고리즘을 이용한 MF의 Hybrid 추천 시스템
>
> 추천 시스템이 조회수 데이터를 기반으로 작동하기 때문에 대규모 데이터를 다뤄야하며,
> 각 사용자에 대해서 충분한 데이터가 없고, 빠른 속도가 필요하기 때문에 IBCF를 적용
>
> * IBCF
>
>     * 정확도는 약간 떨어지지만, 
>
>     1. 사전에 계산하여 저장된 아이템별 유사도를 사용하기 때문에 속도가 빠름
>     2. 안정적인 추천 (터무니 없는 추천의 빈도가 낮음)
>     3. 데이터가 조금 바뀌어도 추천 결과에 큰 영향 X -> 주기적인 데이터 업데이트
>
> * MF
>
>     1. 빠른 반응이 가능
>     2. 유사도는 낮더라도 많은 사람들이 동시에 조회한 카테고리를 추천에 반영 가능

### 3.1 IBCF

* 각 카테고리 간의 유사도와 사용자의 카테고리별 조회수를 기준으로

    특정 카테고리에 대한 사용자의 예측 조회수를 계산합니다.

    (현재는 dummy data를 이용해서 코사인 유사도를 계산한 결과를 Item Similarity로 사용)

* 속도 향상 및 추천 정확도 향상(터무니 없는 예측 제외)를 목적으로

    사용자가 한번이라도 조회한 중분류의 하위 소분류들에 대해서만 예측값을 계산합니다.

    * Ex. 남성 상의 제품만 본 경우
    
* 남성 의류(중분류)의 하위 소분류인 남성 상의, 남성 하의, 남성 잠옷, 남성 언더웨어 항목만 계산
  
* 이를 통해 423개 카테고리의 예측값을 모두 계산하는 것보다 계산 속도도 향상되고, (1.4s -> 0.2s)
  
    터무니없는 추천을 일부 방지할 수 있었습니다.
    
* 단, 특정 소분류의 제품만 지속적으로 추천되는 경우가 있기떄문에,
  
    다양한 소분류를 추천하기 위해 하이브리드 추천 시스템을 구현하게 되었습니다.

### 3.2 MF

* 미리 Model을 저장해두면 빠른 반응이 가능하다는 장점으로 인해 선택

* 초기에는 SGD 알고리즘을 적용하여 추천 시스템을 구현했으나,

    잠재요인 수, 학습률, 정규화 계수, 변수 초기화 등 여러 요인으로 인해 계속해서

    overfitting / 정확도 하락 문제가 발생해서 다른 알고리즘을 적용하게 됨

* SVD 알고리즘을 적용할 경우 빠른 반응이 가능하며, 

    어느정도의 정확도를 확보할 수 있는 것을 실험적으로 확인 => scipy 라이브러리 활용
    
* dummy data에 대해 잠재요인 수 (K)를 변경하며 error를 계산

    최적의 잠재요인 수 도출 (K=15)
    
    |  K   | RMSE Error |
    | :--: | :--------: |
    |  10  |   1.2813   |
    |  11  |   1.2740   |
    |  12  |   1.2662   |
    |  13  |   1.2628   |
    |  14  |   1.2604   |
    |  15  |   1.2586   |
    |  16  |   1.2651   |
    |  17  |   1.2700   |
    |  18  |   1.2727   |
    |  19  |   1.2758   |
    |  20  |   1.2827   |
    
    

### 3.3 Hybrid

* IBCF와 MF를 적절하게 조합한다면,

    추천의 정확도를 높이면서 다양한 카테고리를 추천할 수 있을 것이라고 예상

* 단순히 IBCF로 계산된 예측 조회수와 MF의 예측 조회수를 더해서 Hybrid 추천 시스템을 구현

* 각 Model의 가중치(weight)를 바꾸어가며 모델의 평가 지표인 RMSE를 계산해서

    해당 값이 최소가 되는 weight를 찾아서 그를 적용
    
    weight = 0.51이 최소

```bash
IBCF weight: 0.4
1.2068352475852433
--------------------------------------------------
IBCF weight: 0.41
1.2063340509489258
--------------------------------------------------
IBCF weight: 0.42
1.2058727391433572
--------------------------------------------------
IBCF weight: 0.43
1.2054513579588804
--------------------------------------------------
IBCF weight: 0.44
1.205069949283552
--------------------------------------------------
IBCF weight: 0.45
1.2047285510824268
--------------------------------------------------
IBCF weight: 0.46
1.2044271973787428
--------------------------------------------------
IBCF weight: 0.47
1.204165918237022
--------------------------------------------------
IBCF weight: 0.48
1.2039447397481147
--------------------------------------------------
IBCF weight: 0.49
1.2037636840161976
--------------------------------------------------
IBCF weight: 0.5
1.2036227691477464
--------------------------------------------------
IBCF weight: 0.51
1.203522009242489
--------------------------------------------------
IBCF weight: 0.52
1.2034614143863587
--------------------------------------------------
IBCF weight: 0.53
1.203440990646446
--------------------------------------------------
IBCF weight: 0.54
1.2034607400679642
--------------------------------------------------
IBCF weight: 0.55
1.2035206606732234
--------------------------------------------------
IBCF weight: 0.56
1.2036207464626225
--------------------------------------------------
IBCF weight: 0.57
1.2037609874176505
--------------------------------------------------
IBCF weight: 0.58
1.2039413695058996
--------------------------------------------------
IBCF weight: 0.59
1.204161874688081
--------------------------------------------------
IBCF weight: 0.6
1.2044224809270347
--------------------------------------------------
```



### 참고 자료

1. 각 Model의 RMSE (dummy data를 이용하여 평가)

    * Simple(기본 추천 시스템) : 1.1381
    * IBCF : 1.2470
    * MF : 1.2586 (K = 15)
    * Hybrid : 1.2034 (가중치 0.53)

    현재 dummy data는 각 사용자의 그룹별로 일정한 선택 패턴을 가지도록 구성되어있기 때문에,

    사용자의 그룹별로 추천을 해주는 Simple System이 가장 정확하게 나오지만

    실제 시스템으로 갈 경우 아마도.... RMSE는 바뀔 예정